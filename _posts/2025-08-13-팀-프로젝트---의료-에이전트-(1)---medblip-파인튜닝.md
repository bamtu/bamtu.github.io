---
layout: post
title:  "팀 프로젝트 - 의료 에이전트 (1) - MedBLIP 파인튜닝"
date:   2025-08-13 00:07:27 +0900
categories: AIagent
---

### 팀 프로젝트 시작
---

모두연 AI에이전트랩에서 새로운 팀프로젝트를 시작했다. 

이 프로젝트에서는 MedBLIP 이라는 논문의 출력을 토대로 LLM을 이용하여 환자에게 도움을 준다. MedBLIP은 BLIP(Bootstrapping Language-Image Pre-training for Unified Vision-Language Understanding and Generation) 모델을 ROCO라는 방사선 의료 이미지 셋에 파인튜닝시킨다. 파인튜닝의 가장 큰 이점으로는, 캡션의 정확성 및 전문성 향상이다.


```text
(Before) BLIP: "뇌의 의료 스캔 (a medical scan of the brain)", "큰 가슴의 의료 스캔 (a medical scan of large chest)"
(After) 파인튜닝된 MedBLIP: "좌측 전두엽의 고신호 병변 (hyperintense lesion in the left frontal lobe)", "양측 흉막 삼출을 보이는 흉부 엑스레이 (chest x-ray showing bilateral pleural effusion)"
```

파인튜닝된 BLIP은 의학 용어, 해부학적 구조, 병변 특징 등을 학습하여 훨씬 더 임상적으로 유용하고 구체적이고 풍부한 캡션을 생성할 수 있다. 

<팀 프로젝트 초안>

![](/assets/202508Mo224159.png)

위에서 파인튜닝된 BLIP을 이용해서 생성한 캡션을 받아 다음 LLM의 입력에 넣고, 준비되어있던 증상과 의료 진단 VectorStore에서 필요한 데이터를 검색하여 가져와 LLM이 처리하여 사용자에게 해당하는 이미지에 맞는 증상과 의료진단을 주는 것이 목표이다. 

내 역할은 그 BLIP을 파인튜닝하는 것이었다. transformers 라는 라이브러리를 이용하여 엄청 간단했고, 모델의 크기는 크지않아 빠르게 역할을 수행할 수 있었다. 

기존의 코드에 early stopping을 적용했고, BERT score를 측정하여 validation하는 과정을 추가했고, 인퍼런스하는 과정도 추가하였다. 아래 github 저장소에서 간단한 코드를 확인할 수 있다.

https://github.com/bamtu/ROCOv2_BLIP_finetuning


### 정리
---
새로운 팀 프로젝트를 시작하였고, BLIP을 finetuning하여 캡션의 정확성 및 전문성을 높였다. 