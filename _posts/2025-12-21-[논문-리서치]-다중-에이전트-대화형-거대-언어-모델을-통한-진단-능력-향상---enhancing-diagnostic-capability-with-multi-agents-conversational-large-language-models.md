---
layout: post
title:  "[논문 리서치] Multi Agent활용 의료 에이전트 (2) - 다중 에이전트 대화형 거대 언어 모델을 통한 진단 능력 향상 - Enhancing diagnostic capability with multi-agents conversational large language models"
date:   2025-12-21 20:17:34 +0900
categories: AIagent TeamProject
---


### Background
---
팀프로젝트 기간동안 우리 팀은 의료 진단 분야에서 Multi-agent를 이용해서 최적의 결과를 생성하려고 노력했다. 그래서 논문을 서치하게 되었는데, 서치한 논문 제목은 Enhancing diagnostic capability with multi-agents conversational large language models, 이 논문에서는 다중 에이전트 대화(Multi-Agent Conversation) 프레임워크를 제시한다. 실제 임상 환경에서 여러 전문의가 모여 복잡한 환자 사례를 논의하는 다학제팀(Multi-Disciplinary Team, MDT)토론을 모방하여 설계되었다고 한다. 

논문의 핵심 목표는 단일 언어 모델이 놓칠 수 있는 다양한 관점을 통합하여 진단의 정확성을 높이는 것이다. 이 논문에서는 Langchain이 아니라 AutoGen으로 개발되었다. Udemy같은 강의들도 보니까 Multi Agent를 구현할 때는 AutoGen을 많이 사용하는 경향이 보였다. 하지만 우리 팀은 LangChain, LangGraph를 이용해서 구현하였다.


### 논문의 요약 및 결론
---
논문에서는 에이전트의 구성 방식을 두가지로 나누었는데, 표로 나타내면 다음과 같다.
| 구분 (Category) | 표준 구성 (Standard Configuration) - 기본 방식 | 전문 분야 할당 실험 (Specialty Assignment Experiment) |
|---|---|---|
| 에이전트의 정체성 | 모두 동일한 일반 의사 (Generalist) 에이전트 | 사례에 따라 동적으로 역할이 부여된 전문의 (Specialist) 에이전트 |
| 역할 부여 방식 | 별도의 역할 부여 없음 | 프롬프트를 통해 "당신은 OOO 전문의입니다"라고 지시 |
| 차이점 발생 원인 | 대화 과정에서 자연스럽게 발생하는 다양한 관점과 추론 경로 | 명시적으로 부여된 전문 분야 역할 |
| 성능 | 가장 높은 성능을 보임 | 표준 구성 대비 유의미한 성능 향상 없음 |

이 실험목적은 "의사 에이전트에게 환자 사례에 맞는 특정 전문 분야를 할당하면 진단 정확도가 더 높아질까?"를 확인하기 위함이었다. 

에이전트를 작동시키는 방식은 다음과 같다. 

``` 
1. 먼저 환자 사례를 GPT-4에 입력하여 해당 사례와 가장 관련성이 높은 전문 분야 4개를 식별한다. (예: 심장내과, 영상의학과, 유전학과 등)
2. 그 다음, 4명(2명~5명)의 의사 에이전트에게 각각 프롬프트(Prompt)를 통해 "당신은 지금부터 심장내과 전문의의 역할을 맡아주세요" 와 같이 역할을 명시적으로 지시한다.
```

(역할부여는 생각보다 아주 간단한 방법이다. 의사 에이전트들이 서로 다르게 파인튜닝되었을까? 라고 생각했지만 아니었다. 동일한 에이전트에 롤을 부여하는 것만 다르다.)

결론을 말하자면 의외의 결과가 나왔다. -> 의사 에이전트들이 "각기 다른 역할"을 가질 수 있도록 실험했지만, 이것이 시스템 성능의 핵심 요인은 아니었다. 오히려 **동일한 역할을 가진 여러 에이전트가 하나의 주제를 놓고 자유롭게 토론하고, 감독 에이전트가 이를 조율하는 '협력적 대화 구조' 자체가 성능 향상의 가장 큰 원동력이었다**고 논문은 설명하고 있다.

이 중 가장 성능이 좋았던 최적의 구성은 
``` 
GPT-4를 기본 모델(Base Model)로 사용하는 4명의 의사 에이전트와 1명의 감독 에이전트
```

### 생각하기
---
앞에서 우리는 Multi Agent를 사용하기로 결정했다. 단일 모델의 근본적인 한계점은 무엇일까?  

생활에서 보자. 개개인은 어떤 생각이나 관념 등을 가질 수 있다. 그런데, 이 생각이나 관념은 다른 사람이 봤을 때는 의아할 수 있고, 다른 더 좋은 방법이 있을 수도 있다. 그래서 필요한 것이 미팅이다. 서로 의견을 조율하면서 회사같은 단체가 어떤 방향으로 나갈지 결정한다. 

이 예시에서 하는 것을 에이전트가 따라하게 한다. 즉, 협력과 토론을 모방하게 만든다. 논문에 따르면, 단일 모델의 근본적인 한계점은 다음과 같다. 

1. 선형적이고 피상적인 추론을 한다. - 논문에서는 환자의 증상 중 가장 눈에 띄는 하나에 꽂혀 성급한 결론을 내릴 수 있다고 설명한다. 예를 들어, 심장 염증이 보이면 '심낭염'이라고 진단하고 더 깊은 원인을 파고들지 않을 수 있다. 겉으로 드러난 증상은 맞췄지만, 그 증상을 일으킨 근본적인 희귀 질환(예: 바르데-비들 증후군)은 놓치는 것이다.
2. 자가 교정 및 비판 능력의 부재 - 단일 모델은 스스로의 추론 과정이 잘못되었을 때 그것을 인지하고 다른 관점에서 재검토하는 능력이 부족하다. 한 번 잘못된 가정에 빠지면, 그 가정을 뒷받침하는 그럴듯한 근거를 계속 만들어내면서 Hallucination에 빠진다. 
3. 다양한 가설의 동시 탐색 및 비교의 어려움 - 단일 모델에게 여러 가능한 진단명(감별 진단 목록)을 나열하라고 할 수는 있지만, 그 가설들 사이의 우위를 역동적으로 토론하고 비교하는 과정을 시뮬레이션하지는 못한다.

-> 멀티 에이전트는 이 세가지 한계점들을 해결하는 개념이다. '정답 찾기'라는 단일 프로세스를 '최적의 해결책을 찾아가는 협력적 토론'프로세스로 전환하여, 단일 모델이 가진 사고의 경직성과 편향성을 극복하고 더 깊이 있고 신뢰할 수 있는 결론을 도출한다. 


### 논문에서 더 얻어가야할 것.
---

다음은 구현을 위해 멀티 에이전트를 어떻게 구성해야할지 알아내야했다. 다음의 그림은 논문의 multi-agent conversation (MAC) 프레임워크 구성 그림이다. 


![](../_assets/20251221231828.png)

먼저 맨 왼쪽에 Admin Agent가 있다. Admin Agent는 대화의 시작점이자, 다른 에이전트에게 환자의 정보(기본 정보, 임상 증상, 병력, 검사 결과 등)와 해결해야 할 과제(예: "가장 가능성 있는 진단명과 추가 검사를 제안하시오")를 전달한다. 

다음으로 의사 에이전트들이 conversation을 진행한다. 제안하고, 토론하고, 의견 수정과 개선을 한다. 이렇게 한 라운드의 대화가 끝나면 Supervisor Agent가 진단과 제안을 평가하여 비판적 질문을 하고, 합의를 유도한다. 라운드가 계속되고, 최대 13라운드에 도달하거나, 에이전트들이 충분한 합의에 도달했다고 판단하면 대화를 종료시킨다. 


### 결론
---
프로젝트의 진행을 위해 의료 진단 분야에서 멀티 에이전트를 적용한 논문을 리서치했다. 결과는 의외로, 모두 같은 롤을 수행하는 의사들의 Conversation으로 나온 결과가 가장 좋았다. 



### 출처
---

논문 - https://www.nature.com/articles/s41746-025-01550-0